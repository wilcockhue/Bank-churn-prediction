{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":4336.484731,"end_time":"2024-09-10T16:05:58.969021","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-10T14:53:42.484290","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport sys\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.509079,"end_time":"2024-09-10T14:53:46.349614","exception":false,"start_time":"2024-09-10T14:53:45.840535","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:22:40.621257Z","iopub.execute_input":"2024-09-14T05:22:40.621789Z","iopub.status.idle":"2024-09-14T05:22:40.636370Z","shell.execute_reply.started":"2024-09-14T05:22:40.621738Z","shell.execute_reply":"2024-09-14T05:22:40.634944Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/concepts.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/mcts_gateway.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/__init__.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/mcts_inference_server.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/templates.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/relay.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/__init__.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"papermill":{"duration":0.03421,"end_time":"2024-09-10T14:53:46.393282","exception":false,"start_time":"2024-09-10T14:53:46.359072","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:22:40.639176Z","iopub.execute_input":"2024-09-14T05:22:40.639792Z","iopub.status.idle":"2024-09-14T05:22:40.660785Z","shell.execute_reply.started":"2024-09-14T05:22:40.639713Z","shell.execute_reply":"2024-09-14T05:22:40.659413Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train = import_data('/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv')\ntest = import_data('/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv')\n","metadata":{"papermill":{"duration":43.711495,"end_time":"2024-09-10T14:54:30.113811","exception":false,"start_time":"2024-09-10T14:53:46.402316","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:22:40.872976Z","iopub.execute_input":"2024-09-14T05:22:40.873458Z","iopub.status.idle":"2024-09-14T05:23:09.255157Z","shell.execute_reply.started":"2024-09-14T05:22:40.873410Z","shell.execute_reply":"2024-09-14T05:23:09.253069Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/147790395.py:42: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n  df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n","output_type":"stream"},{"name":"stdout","text":"Memory usage of dataframe is 1448.46 MB\nMemory usage after optimization is: 259.71 MB\nDecreased by 82.1%\nMemory usage of dataframe is 0.02 MB\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/147790395.py:42: FutureWarning: The 'keep_date_col' keyword in pd.read_csv is deprecated and will be removed in a future version. Explicitly remove unwanted columns after parsing instead.\n  df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n","output_type":"stream"},{"name":"stdout","text":"Memory usage after optimization is: 0.00 MB\nDecreased by 79.1%\n","output_type":"stream"}]},{"cell_type":"code","source":"\n  # Get a summary of the dataset including column types and non-null counts\n","metadata":{"papermill":{"duration":0.060177,"end_time":"2024-09-10T14:54:30.183865","exception":false,"start_time":"2024-09-10T14:54:30.123688","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:23:09.259012Z","iopub.execute_input":"2024-09-14T05:23:09.259475Z","iopub.status.idle":"2024-09-14T05:23:09.265271Z","shell.execute_reply.started":"2024-09-14T05:23:09.259424Z","shell.execute_reply":"2024-09-14T05:23:09.263781Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"y = train[['utility_agent1']]\nX = train.drop(['utility_agent1'], axis=1)\nX = X.drop(['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1'], axis=1)","metadata":{"papermill":{"duration":0.659311,"end_time":"2024-09-10T14:54:32.025203","exception":false,"start_time":"2024-09-10T14:54:31.365892","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:23:09.266994Z","iopub.execute_input":"2024-09-14T05:23:09.267481Z","iopub.status.idle":"2024-09-14T05:23:10.720165Z","shell.execute_reply.started":"2024-09-14T05:23:09.267435Z","shell.execute_reply":"2024-09-14T05:23:10.718774Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"missing_percentage = X.isna().mean() * 100\ndef drop_missing_data(df):\n# Drop columns with more than 50% missing values\n    df = df.drop(columns=missing_percentage[missing_percentage > 50].index)\n    return df\nX = drop_missing_data(X)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:23:10.723859Z","iopub.execute_input":"2024-09-14T05:23:10.724402Z","iopub.status.idle":"2024-09-14T05:23:11.755830Z","shell.execute_reply.started":"2024-09-14T05:23:10.724344Z","shell.execute_reply":"2024-09-14T05:23:11.754529Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":" unique_counts = X.nunique()\ndef drop_nonunique_values(df):\n    print(unique_counts)\n# Drop columns with only one unique value\n    df = df.drop(columns=unique_counts[unique_counts == 1].index)\n    return df\nX = drop_nonunique_values(X)","metadata":{"papermill":{"duration":1.904333,"end_time":"2024-09-10T14:54:33.939959","exception":false,"start_time":"2024-09-10T14:54:32.035626","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:23:11.759889Z","iopub.execute_input":"2024-09-14T05:23:11.760345Z","iopub.status.idle":"2024-09-14T05:23:13.681620Z","shell.execute_reply.started":"2024-09-14T05:23:11.760299Z","shell.execute_reply":"2024-09-14T05:23:13.680224Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Id                   233234\nGameRulesetName        1377\nagent1                   72\nagent2                   72\nProperties                1\n                      ...  \nTrigger                   2\nPlayoutsPerSecond      1369\nMovesPerSecond         1377\nEnglishRules           1328\nLudRules               1373\nLength: 792, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"def columns_transform(X):\n# Split 'agent1' into 5 parts and assign to new columns\n    global ct\n    X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n\n# Split 'agent2' into 5 parts and assign to new columns\n    X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n\n\n    X = X.drop(['Id','agent1','agent2'], axis=1)\n\n    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n\n    num_feat = X.select_dtypes('number').columns\n    feature_names = X.columns\n\n    from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n    cat_encoder = OrdinalEncoder()\n    std = StandardScaler()\n    from sklearn.compose import ColumnTransformer\n    ct = ColumnTransformer([('cat', cat_encoder, categorical_features), ('std', StandardScaler(), num_feat)])\n    X = ct.fit_transform(X)\n    return X\nX = columns_transform(X)\n\n\n","metadata":{"papermill":{"duration":1.085271,"end_time":"2024-09-10T14:54:35.036105","exception":false,"start_time":"2024-09-10T14:54:33.950834","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-14T05:23:13.684227Z","iopub.execute_input":"2024-09-14T05:23:13.684629Z","iopub.status.idle":"2024-09-14T05:23:19.661686Z","shell.execute_reply.started":"2024-09-14T05:23:13.684589Z","shell.execute_reply":"2024-09-14T05:23:19.660502Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model():\n    from sklearn.decomposition import PCA\n    global pca, lgbm_reg\n# Reduce to 100 principal components\n    pca = PCA(n_components=100)\n    X_pca = pca.fit_transform(X)\n    from sklearn.model_selection import train_test_split\n    X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n    import lightgbm as lgb\n    lgbm_reg = lgb.LGBMRegressor(\n        learning_rate=0.05,\n        num_leaves=50,\n        n_estimators=1500,\n        min_child_samples=42,\n        subsample=0.8,\n        colsample_bytree=0.9,\n        reg_alpha=0.001,\n        reg_lambda=0.02,\n        min_split_gain=0.001,\n        min_child_weight=0.002)        # Use GPU for faster training\n    \n    lgbm_reg.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n    y_predict = lgbm_reg.predict(X_valid)\n\n# Evaluate the model\n    from sklearn.metrics import mean_squared_error\n    import numpy as np\n\n# Calculate RMSE\n    rmse = np.sqrt(mean_squared_error(y_valid, y_predict))\n    print(f'Validation RMSE: {rmse:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:23:19.666391Z","iopub.execute_input":"2024-09-14T05:23:19.666974Z","iopub.status.idle":"2024-09-14T05:23:19.679429Z","shell.execute_reply.started":"2024-09-14T05:23:19.666913Z","shell.execute_reply":"2024-09-14T05:23:19.677992Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:23:19.681356Z","iopub.execute_input":"2024-09-14T05:23:19.681934Z","iopub.status.idle":"2024-09-14T05:23:19.725920Z","shell.execute_reply.started":"2024-09-14T05:23:19.681870Z","shell.execute_reply":"2024-09-14T05:23:19.724677Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"       Id GameRulesetName                                 agent1  \\\n0  233234             00Y                MCTS-UCB1-0.6-NST-false   \n1  233235             00Y  MCTS-ProgressiveHistory-0.1-MAST-true   \n2  233236             00Y      MCTS-UCB1Tuned-0.1-Random200-true   \n\n                                  agent2  Properties  Format  Time  Discrete  \\\n0  MCTS-ProgressiveHistory-0.1-MAST-true           1       1     1         1   \n1                MCTS-UCB1-0.6-NST-false           1       1     1         1   \n2  MCTS-ProgressiveHistory-0.1-MAST-true           1       1     1         1   \n\n   Realtime  Turns  ...  Efficiency  CopyContext  Then  ForEachPiece  \\\n0         0      1  ...           1            0     1             0   \n1         0      1  ...           1            0     1             0   \n2         0      1  ...           1            0     1             0   \n\n   DoLudeme  Trigger  PlayoutsPerSecond  MovesPerSecond  \\\n0         0        1              298.0         18880.0   \n1         0        1              298.0         18880.0   \n2         0        1              298.0         18880.0   \n\n                                        EnglishRules  \\\n0  Goal: Connect all three edge colors with a sin...   \n1  Goal: Connect all three edge colors with a sin...   \n2  Goal: Connect all three edge colors with a sin...   \n\n                                            LudRules  \n0  (game \"00'Y'\" (players 2) (equipment { (board ...  \n1  (game \"00'Y'\" (players 2) (equipment { (board ...  \n2  (game \"00'Y'\" (players 2) (equipment { (board ...  \n\n[3 rows x 810 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>GameRulesetName</th>\n      <th>agent1</th>\n      <th>agent2</th>\n      <th>Properties</th>\n      <th>Format</th>\n      <th>Time</th>\n      <th>Discrete</th>\n      <th>Realtime</th>\n      <th>Turns</th>\n      <th>...</th>\n      <th>Efficiency</th>\n      <th>CopyContext</th>\n      <th>Then</th>\n      <th>ForEachPiece</th>\n      <th>DoLudeme</th>\n      <th>Trigger</th>\n      <th>PlayoutsPerSecond</th>\n      <th>MovesPerSecond</th>\n      <th>EnglishRules</th>\n      <th>LudRules</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>233234</td>\n      <td>00Y</td>\n      <td>MCTS-UCB1-0.6-NST-false</td>\n      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>298.0</td>\n      <td>18880.0</td>\n      <td>Goal: Connect all three edge colors with a sin...</td>\n      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>233235</td>\n      <td>00Y</td>\n      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n      <td>MCTS-UCB1-0.6-NST-false</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>298.0</td>\n      <td>18880.0</td>\n      <td>Goal: Connect all three edge colors with a sin...</td>\n      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>233236</td>\n      <td>00Y</td>\n      <td>MCTS-UCB1Tuned-0.1-Random200-true</td>\n      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>298.0</td>\n      <td>18880.0</td>\n      <td>Goal: Connect all three edge colors with a sin...</td>\n      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 810 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import polars as pl  # Assuming you're using the `pl.Series` from the Polars library\n\ncounter = 0\ndef predict(test):\n    global counter\n    \n    if counter == 0:\n        # Train the model only the first time predict is called\n        train_model()  # Ensure train_model() trains the LightGBM model (lgbm_reg)\n    \n    counter += 1\n    \n    # Step 1: Preprocess the test data\n    test = drop_missing_data(test) # Drop rows or columns with missing data\n    test = drop_nonunique_values(test)# Remove non-unique columns (e.g., constant features)\n    test = columns_transform(test)  # Apply any additional transformations (e.g., encoding)\n    \n    # Step 2: Apply PCA transformation if needed (Ensure 'pca' is already fitted)\n    test = pca.transform(test)  # This step assumes `pca` is a previously fitted PCA model\n    \n    # Step 3: Make predictions using the trained LightGBM model\n    predictions = lgbm_reg.predict(test)  # lgbm_reg should be your trained LightGBM model\n    \n    # Step 4: Add the predictions as a new column in the submission DataFrame\n    # Ensure `target` is the name of the target column\n    return predictions\npredict(test)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:23:19.727401Z","iopub.execute_input":"2024-09-14T05:23:19.727840Z","iopub.status.idle":"2024-09-14T05:27:40.739536Z","shell.execute_reply.started":"2024-09-14T05:23:19.727795Z","shell.execute_reply":"2024-09-14T05:27:40.738166Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.387254 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25500\n[LightGBM] [Info] Number of data points in the train set: 186587, number of used features: 100\n[LightGBM] [Info] Start training from score 0.043666\nValidation RMSE: 0.4042\nId                   233234\nGameRulesetName        1377\nagent1                   72\nagent2                   72\nProperties                1\n                      ...  \nTrigger                   2\nPlayoutsPerSecond      1369\nMovesPerSecond         1377\nEnglishRules           1328\nLudRules               1373\nLength: 792, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent1_part1', 'agent1_part2', 'agent1_part3', 'agent1_part4', 'agent1_part5']] = X['agent1'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n/tmp/ipykernel_36/2832442871.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  X[['agent2_part1', 'agent2_part2', 'agent2_part3', 'agent2_part4', 'agent2_part5']] = X['agent2'].str.split('-', expand=True)\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"array([0.06895117, 0.03908677, 0.09870924])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}